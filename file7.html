
    <!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title></title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Mobile properties -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">


  <!-- Stylesheets -->
  <link rel="stylesheet" href="css/output.68349477b267.css" type="text/css">

  <link rel="stylesheet" href="css/output.e1a9b6ead5ea.css" type="text/css">
  <link rel="stylesheet" href="css/output.ee7723a5b71e.css" type="text/css">
  <link rel="stylesheet" href="css/output.3766d7ad0d2d.css" type="text/css">
  <link rel="stylesheet" href="css/output.e3c3c2c84eb3.css" type="text/css">


  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />

  <link type="text/css" href="css/base.6539a0a78536cfdc1fa6.css" rel="stylesheet" />


  <link rel="stylesheet" href="css/fonts/stix/stixfonts.css" type="text/css" />
  <link rel="stylesheet" href="css/3.18/pmcrefs1.min.css" type="text/css" />
  <link rel="stylesheet" href="css/pmc2020_1.1/ncbi_web.min.css?_=a" type="text/css" />
  <style type="text/css">
    .pmc-wm {
      background: transparent repeat-y top left;
      background-size: auto, contain
    }
  </style>
  <style type="text/css">
    .print-view {
      display: block
    }
  </style>

  <link type="text/css" href="css/article.053deb6b9728571514ad.css" rel="stylesheet" />
  <link type="text/css" href="css/cite-box.css" rel="stylesheet" />
  </head>

        Generative Adversarial Nets<br>Ian J. Goodfellow, Jean Pouget-Abadiey, Mehdi Mirza, Bing Xu, David Warde-Farley,<br>Sherjil Ozairz, Aaron Courville, Yoshua Bengiox<br>D¬¥epartement d‚Äôinformatique et de recherche op ¬¥erationnelle<br>Universit ¬¥e de Montr ¬¥eal<br>Montr ¬¥eal, QC H3C 3J7<br>Abstract<br>We propose a new framework for estimating generative models via an adversar-<br>ial process, in which we simultaneously train two models: a generative model G<br>that captures the data distribution, and a discriminative model Dthat estimates<br>the probability that a sample came from the training data rather than G. The train-<br>ing procedure for Gis to maximize the probability of Dmaking a mistake. This<br>framework corresponds to a minimax two-player game. In the space of arbitrary<br>functionsGandD, a unique solution exists, with Grecovering the training data<br>distribution and Dequal to1<br>2everywhere. In the case where GandDare deÔ¨Åned<br>by multilayer perceptrons, the entire system can be trained with backpropagation.<br>There is no need for any Markov chains or unrolled approximate inference net-<br>works during either training or generation of samples. Experiments demonstrate<br>the potential of the framework through qualitative and quantitative evaluation of<br>the generated samples.<br>1 Introduction<br>The promise of deep learning is to discover rich, hierarchical models [<a href='#ref2' rid='ref2' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>2</a>] that represent probability<br>distributions over the kinds of data encountered in artiÔ¨Åcial intelligence applications, such as natural<br>images, audio waveforms containing speech, and symbols in natural language corpora. So far, the<br>most striking successes in deep learning have involved discriminative models, usually those that<br>map a high-dimensional, rich sensory input to a class label [<a href='#ref14' rid='ref14' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>14</a>, <a href='#ref20' rid='ref20' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>20</a>]. These striking successes have<br>primarily been based on the backpropagation and dropout algorithms, using piecewise linear units<br>[<a href='#ref17' rid='ref17' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>17</a>, <a href='#ref8' rid='ref8' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>8</a>, <a href='#ref9' rid='ref9' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>9</a>] which have a particularly well-behaved gradient . Deep generative models have had less<br>of an impact, due to the difÔ¨Åculty of approximating many intractable probabilistic computations that<br>arise in maximum likelihood estimation and related strategies, and due to difÔ¨Åculty of leveraging<br>the beneÔ¨Åts of piecewise linear units in the generative context. We propose a new generative model<br>estimation procedure that sidesteps these difÔ¨Åculties.1<br>In the proposed adversarial nets framework, the generative model is pitted against an adversary: a<br>discriminative model that learns to determine whether a sample is from the model distribution or the<br>data distribution. The generative model can be thought of as analogous to a team of counterfeiters,<br>trying to produce fake currency and use it without detection, while the discriminative model is<br>analogous to the police, trying to detect the counterfeit currency. Competition in this game drives<br>both teams to improve their methods until the counterfeits are indistiguishable from the genuine<br>articles.<br>Ian Goodfellow is now a research scientist at Google, but did this work earlier as a UdeM student<br>yJean Pouget-Abadie did this work while visiting Universit ¬¥e de Montr ¬¥eal from Ecole Polytechnique.<br>zSherjil Ozair is visiting Universit ¬¥e de Montr ¬¥eal from Indian Institute of Technology Delhi<br>xYoshua Bengio is a CIFAR Senior Fellow.<br>1All code and hyperparameters available at http://www.github.com/goodfeli/adversarial<br>1This framework can yield speciÔ¨Åc training algorithms for many kinds of model and optimization<br>algorithm. In this article, we explore the special case when the generative model generates samples<br>by passing random noise through a multilayer perceptron, and the discriminative model is also a<br>multilayer perceptron. We refer to this special case as adversarial nets . In this case, we can train<br>both models using only the highly successful backpropagation and dropout algorithms [<a href='#ref16' rid='ref16' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>16</a>] and<br>sample from the generative model using only forward propagation. No approximate inference or<br>Markov chains are necessary.<br>2 Related work<br>Until recently, most work on deep generative models focused on models that provided a parametric<br>speciÔ¨Åcation of a probability distribution function. The model can then be trained by maximiz-<br>ing the log likelihood. In this family of model, perhaps the most succesful is the deep Boltzmann<br>machine [<a href='#ref25' rid='ref25' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>25</a>]. Such models generally have intractable likelihood functions and therefore require<br>numerous approximations to the likelihood gradient. These difÔ¨Åculties motivated the development<br>of ‚Äúgenerative machines‚Äù‚Äìmodels that do not explicitly represent the likelihood, yet are able to gen-<br>erate samples from the desired distribution. Generative stochastic networks [<a href='#ref4' rid='ref4' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>4</a>] are an example of<br>a generative machine that can be trained with exact backpropagation rather than the numerous ap-<br>proximations required for Boltzmann machines. This work extends the idea of a generative machine<br>by eliminating the Markov chains used in generative stochastic networks.<br>Our work backpropagates derivatives through generative processes by using the observation that<br>lim<br>!0rxEN (0;2I)f(x+) =rxf(x):<br>We were unaware at the time we developed this work that Kingma and Welling [<a href='#ref18' rid='ref18' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>18</a>] and Rezende<br>et al. [<a href='#ref23' rid='ref23' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>23</a>] had developed more general stochastic backpropagation rules, allowing one to backprop-<br>agate through Gaussian distributions with Ô¨Ånite variance, and to backpropagate to the covariance<br>parameter as well as the mean. These backpropagation rules could allow one to learn the condi-<br>tional variance of the generator, which we treated as a hyperparameter in this work. Kingma and<br>Welling [<a href='#ref18' rid='ref18' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>18</a>] and Rezende et al. [<a href='#ref23' rid='ref23' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>23</a>] use stochastic backpropagation to train variational autoen-<br>coders (V AEs). Like generative adversarial networks, variational autoencoders pair a differentiable<br>generator network with a second neural network. Unlike generative adversarial networks, the sec-<br>ond network in a V AE is a recognition model that performs approximate inference. GANs require<br>differentiation through the visible units, and thus cannot model discrete data, while V AEs require<br>differentiation through the hidden units, and thus cannot have discrete latent variables. Other V AE-<br>like approaches exist [<a href='#ref12' rid='ref12' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>12</a>, <a href='#ref22' rid='ref22' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>22</a>] but are less closely related to our method.<br>Previous work has also taken the approach of using a discriminative criterion to train a generative<br>model [<a href='#ref29' rid='ref29' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>29</a>, <a href='#ref13' rid='ref13' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>13</a>]. These approaches use criteria that are intractable for deep generative models. These<br>methods are difÔ¨Åcult even to approximate for deep models because they involve ratios of probabili-<br>ties which cannot be approximated using variational approximations that lower bound the probabil-<br>ity. Noise-contrastive estimation (NCE) [<a href='#ref13' rid='ref13' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>13</a>] involves training a generative model by learning the<br>weights that make the model useful for discriminating data from a Ô¨Åxed noise distribution. Using a<br>previously trained model as the noise distribution allows training a sequence of models of increasing<br>quality. This can be seen as an informal competition mechanism similar in spirit to the formal com-<br>petition used in the adversarial networks game. The key limitation of NCE is that its ‚Äúdiscriminator‚Äù<br>is deÔ¨Åned by the ratio of the probability densities of the noise distribution and the model distribution,<br>and thus requires the ability to evaluate and backpropagate through both densities.<br>Some previous work has used the general concept of having two neural networks compete. The most<br>relevant work is predictability minimization [<a href='#ref26' rid='ref26' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>26</a>]. In predictability minimization, each hidden unit<br>in a neural network is trained to be different from the output of a second network, which predicts<br>the value of that hidden unit given the value of all of the other hidden units. This work differs from<br>predictability minimization in three important ways: 1) in this work, the competition between the<br>networks is the sole training criterion, and is sufÔ¨Åcient on its own to train the network. Predictability<br>minimization is only a regularizer that encourages the hidden units of a neural network to be sta-<br>tistically independent while they accomplish some other task; it is not a primary training criterion.<br>2) The nature of the competition is different. In predictability minimization, two networks‚Äô outputs<br>are compared, with one network trying to make the outputs similar and the other trying to make the<br>2outputs different. The output in question is a single scalar. In GANs, one network produces a rich,<br>high dimensional vector that is used as the input to another network, and attempts to choose an input<br>that the other network does not know how to process. 3) The speciÔ¨Åcation of the learning process<br>is different. Predictability minimization is described as an optimization problem with an objective<br>function to be minimized, and learning approaches the minimum of the objective function. GANs<br>are based on a minimax game rather than an optimization problem, and have a value function that<br>one agent seeks to maximize and the other seeks to minimize. The game terminates at a saddle point<br>that is a minimum with respect to one player‚Äôs strategy and a maximum with respect to the other<br>player‚Äôs strategy.<br>Generative adversarial networks has been sometimes confused with the related concept of ‚Äúadversar-<br>ial examples‚Äù [<a href='#ref28' rid='ref28' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>28</a>]. Adversarial examples are examples found by using gradient-based optimization<br>directly on the input to a classiÔ¨Åcation network, in order to Ô¨Ånd examples that are similar to the<br>data yet misclassiÔ¨Åed. This is different from the present work because adversarial examples are<br>not a mechanism for training a generative model. Instead, adversarial examples are primarily an<br>analysis tool for showing that neural networks behave in intriguing ways, often conÔ¨Ådently clas-<br>sifying two images differently with high conÔ¨Ådence even though the difference between them is<br>imperceptible to a human observer. The existence of such adversarial examples does suggest that<br>generative adversarial network training could be inefÔ¨Åcient, because they show that it is possible to<br>make modern discriminative networks conÔ¨Ådently recognize a class without emulating any of the<br>human-perceptible attributes of that class.<br>3 Adversarial nets<br>The adversarial modeling framework is most straightforward to apply when the models are both<br>multilayer perceptrons. To learn the generator‚Äôs distribution pgover data x, we deÔ¨Åne a prior on<br>input noise variables pz(z), then represent a mapping to data space as G(z;g), whereGis a<br>differentiable function represented by a multilayer perceptron with parameters g. We also deÔ¨Åne a<br>second multilayer perceptron D(x;d)that outputs a single scalar. D(x)represents the probability<br>thatxcame from the data rather than pg. We trainDto maximize the probability of assigning the<br>correct label to both training examples and samples from G. We simultaneously train Gto minimize<br>log(1 D(G(z))). In other words, DandGplay the following two-player minimax game with<br>value function V(G;D ):<br>min<br>Gmax<br>DV(D;G ) =Expdata(x)[logD(x)] +Ezpz(z)[log(1 D(G(z)))]: (1)<br>In the next section, we present a theoretical analysis of adversarial nets, essentially showing that<br>the training criterion allows one to recover the data generating distribution as GandDare given<br>enough capacity, i.e., in the non-parametric limit. See Figure 1 for a less formal, more pedagogical<br>explanation of the approach. In practice, we must implement the game using an iterative, numerical<br>approach. Optimizing Dto completion in the inner loop of training is computationally prohibitive,<br>and on Ô¨Ånite datasets would result in overÔ¨Åtting. Instead, we alternate between ksteps of optimizing<br>Dand one step of optimizing G. This results in Dbeing maintained near its optimal solution, so<br>long asGchanges slowly enough. The procedure is formally presented in Algorithm 1.<br>In practice, equation 1 may not provide sufÔ¨Åcient gradient for Gto learn well. Early in learning,<br>whenGis poor,Dcan reject samples with high conÔ¨Ådence because they are clearly different from<br>the training data. In this case, log(1 D(G(z)))saturates. Rather than training Gto minimize<br>log(1 D(G(z)))we can train Gto maximize logD(G(z)). This objective function results in the<br>same Ô¨Åxed point of the dynamics of GandDbut provides much stronger gradients early in learning.<br>4 Theoretical Results<br>The generator Gimplicitly deÔ¨Ånes a probability distribution pgas the distribution of the samples<br>G(z)obtained when zpz. Therefore, we would like Algorithm 1 to converge to a good estimator<br>ofpdata, if given enough capacity and training time. The results of this section are done in a non-<br>parametric setting, e.g. we represent a model with inÔ¨Ånite capacity by studying convergence in the<br>space of probability density functions.<br>We will show in section 4.1 that this minimax game has a global optimum for pg=pdata. We will<br>then show in section 4.2 that Algorithm 1 optimizes Eq 1, thus obtaining the desired result.<br>3x<br>z<br>X<br>Z<br>X<br>Z<br>. . .<br>X<br>Z<br>(a) (b) (c) (d)<br>Figure 1: Generative adversarial nets are trained by simultaneously updating the discriminative distribution<br>(D, blue, dashed line) so that it discriminates between samples from the data generating distribution (black,<br>dotted line)pxfrom those of the generative distribution pg(G) (green, solid line). The lower horizontal line is<br>the domain from which zis sampled, in this case uniformly. The horizontal line above is part of the domain<br>ofx. The upward arrows show how the mapping x=G(z)imposes the non-uniform distribution pgon<br>transformed samples. Gcontracts in regions of high density and expands in regions of low density of pg. (a)<br>Consider an adversarial pair near convergence: pgis similar to pdataandDis a partially accurate classiÔ¨Åer.<br>(b) In the inner loop of the algorithm Dis trained to discriminate samples from data, converging to D(x) =<br>pdata(x)<br>pdata(x)+pg(x). (c) After an update to G, gradient of Dhas guidedG(z)to Ô¨Çow to regions that are more likely<br>to be classiÔ¨Åed as data. (d) After several steps of training, if GandDhave enough capacity, they will reach a<br>point at which both cannot improve because pg=pdata. The discriminator is unable to differentiate between<br>the two distributions, i.e. D(x) =1<br>2.<br>Algorithm 1 Minibatch stochastic gradient descent training of generative adversarial nets. The number of<br>steps to apply to the discriminator, k, is a hyperparameter. We used k= 1, the least expensive option, in our<br>experiments.<br>fornumber of training iterations do<br>forksteps do<br>Sample minibatch of mnoise samplesfz(1);:::; z(m)gfrom noise prior pg(z).<br>Sample minibatch of mexamplesfx(1);:::; x(m)gfrom data generating distribution<br>pdata(x).<br>Update the discriminator by ascending its stochastic gradient:<br>rd1<br>mmX<br>i=1h<br>logD<br>x(i)<br>+ log<br>1 D<br>G<br>z(i)i<br>:<br>end for<br>Sample minibatch of mnoise samplesfz(1);:::; z(m)gfrom noise prior pg(z).<br>Update the generator by descending its stochastic gradient:<br>rg1<br>mmX<br>i=1log<br>1 D<br>G<br>z(i)<br>:<br>end for<br>The gradient-based updates can use any standard gradient-based learning rule. We used momen-<br>tum in our experiments.<br>4.1 Global Optimality of pg=pdata<br>We Ô¨Årst consider the optimal discriminator Dfor any given generator G.<br>Proposition 1. ForGÔ¨Åxed, the optimal discriminator Dis<br>D<br>G(x) =pdata(x)<br>pdata(x) +pg(x)(2)<br>4Proof. The training criterion for the discriminator D, given any generator G, is to maximize the<br>quantityV(G;D )<br>V(G;D ) =Z<br>xpdata(x) log(D(x))dx+Z<br>zpz(z) log(1 D(g(z)))dz<br>=Z<br>xpdata(x) log(D(x)) +pg(x) log(1 D(x))dx (3)<br>For any (a;b)2R2nf0;0g, the function y!alog(y) +blog(1 y)achieves its maximum in<br>[0;1]ata<br>a+b. The discriminator does not need to be deÔ¨Åned outside of Supp (pdata)[Supp (pg),<br>concluding the proof.<br>Note that the training objective for Dcan be interpreted as maximizing the log-likelihood for es-<br>timating the conditional probability P(Y=yjx), whereYindicates whether xcomes from pdata<br>(withy= 1) or frompg(withy= 0). The minimax game in Eq. 1 can now be reformulated as:<br>C(G) = max<br>DV(G;D )<br>=Expdata[logD<br>G(x)] +Ezpz[log(1 D<br>G(G(z)))] (4)<br>=Expdata[logD<br>G(x)] +Expg[log(1 D<br>G(x))]<br>=Expdata<br>logpdata(x)<br>Pdata(x) +pg(x)<br>+Expg<br>logpg(x)<br>pdata(x) +pg(x)<br>Theorem 1. The global minimum of the virtual training criterion C(G)is achieved if and only if<br>pg=pdata. At that point, C(G)achieves the value  log 4 .<br>Proof. Forpg=pdata,D<br>G(x) =1<br>2, (consider Eq. 2). Hence, by inspecting Eq. 4 at D<br>G(x) =1<br>2, we<br>Ô¨ÅndC(G) = log1<br>2+ log1<br>2= log 4 . To see that this is the best possible value of C(G), reached<br>only forpg=pdata, observe that<br>Expdata[ log 2] + Expg[ log 2] = log 4<br>and that by subtracting this expression from C(G) =V(D<br>G;G), we obtain:<br>C(G) = log(4) +KL<br>pdatapdata+pg<br>2<br>+KL<br>pgpdata+pg<br>2<br>(5)<br>where KL is the Kullback‚ÄìLeibler divergence. We recognize in the previous expression the Jensen‚Äì<br>Shannon divergence between the model‚Äôs distribution and the data generating process:<br>C(G) = log(4) + 2JSD (pdatakpg) (6)<br>Since the Jensen‚ÄìShannon divergence between two distributions is always non-negative, and zero<br>iff they are equal, we have shown that C= log(4) is the global minimum of C(G)and that the<br>only solution is pg=pdata, i.e., the generative model perfectly replicating the data distribution.<br>4.2 Convergence of Algorithm 1<br>Proposition 2. IfGandDhave enough capacity, and at each step of Algorithm 1, the discriminator<br>is allowed to reach its optimum given G, andpgis updated so as to improve the criterion<br>Expdata[logD<br>G(x)] +Expg[log(1 D<br>G(x))]<br>thenpgconverges to pdata<br>Proof. ConsiderV(G;D ) =U(pg;D)as a function of pgas done in the above criterion. Note<br>thatU(pg;D)is convex in pg. The subderivatives of a supremum of convex functions include the<br>derivative of the function at the point where the maximum is attained. In other words, if f(x) =<br>sup2Af(x)andf(x)is convex in xfor every, then@f(x)2@fif= arg sup2Af(x).<br>This is equivalent to computing a gradient descent update for pgat the optimal Dgiven the cor-<br>respondingG.supDU(pg;D)is convex in pgwith a unique global optima as proven in Thm 1,<br>therefore with sufÔ¨Åciently small updates of pg,pgconverges to px, concluding the proof.<br>In practice, adversarial nets represent a limited family of pgdistributions via the function G(z;g),<br>and we optimize grather thanpgitself, so the proofs do not apply. However, the excellent perfor-<br>mance of multilayer perceptrons in practice suggests that they are a reasonable model to use despite<br>their lack of theoretical guarantees.<br>5Model MNIST TFD<br>DBN [<a href='#ref3' rid='ref3' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>3</a>] 1382 190966<br>Stacked CAE [<a href='#ref3' rid='ref3' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>3</a>] 1211:6211050<br>Deep GSN [<a href='#ref5' rid='ref5' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>5</a>] 2141:1189029<br>Adversarial nets 2252205726<br>Table 1: Parzen window-based log-likelihood estimates. The reported numbers on MNIST are the mean log-<br>likelihood of samples on test set, with the standard error of the mean computed across examples. On TFD, we<br>computed the standard error across folds of the dataset, with a different chosen using the validation set of<br>each fold. On TFD, was cross validated on each fold and mean log-likelihood on each fold were computed.<br>For MNIST we compare against other models of the real-valued (rather than binary) version of dataset.<br>5 Experiments<br>We trained adversarial nets an a range of datasets including MNIST[<a href='#ref21' rid='ref21' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>21</a>], the Toronto Face Database<br>(TFD) [<a href='#ref27' rid='ref27' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>27</a>], and CIFAR-10 [<a href='#ref19' rid='ref19' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>19</a>]. The generator nets used a mixture of rectiÔ¨Åer linear activations [17,<br>8] and sigmoid activations, while the discriminator net used maxout [<a href='#ref9' rid='ref9' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>9</a>] activations. Dropout [<a href='#ref16' rid='ref16' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>16</a>]<br>was applied in training the discriminator net. While our theoretical framework permits the use of<br>dropout and other noise at intermediate layers of the generator, we used noise as the input to only<br>the bottommost layer of the generator network.<br>We estimate probability of the test set data under pgby Ô¨Åtting a Gaussian Parzen window to the<br>samples generated with Gand reporting the log-likelihood under this distribution. The parameter<br>of the Gaussians was obtained by cross validation on the validation set. This procedure was intro-<br>duced in Breuleux et al. [<a href='#ref7' rid='ref7' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>7</a>] and used for various generative models for which the exact likelihood<br>is not tractable [<a href='#ref24' rid='ref24' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>24</a>, <a href='#ref3' rid='ref3' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>3</a>, <a href='#ref4' rid='ref4' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>4</a>]. Results are reported in Table 1. This method of estimating the likelihood<br>has somewhat high variance and does not perform well in high dimensional spaces but it is the best<br>method available to our knowledge. Advances in generative models that can sample but not estimate<br>likelihood directly motivate further research into how to evaluate such models. In Figures 2 and 3<br>we show samples drawn from the generator net after training. While we make no claim that these<br>samples are better than samples generated by existing methods, we believe that these samples are at<br>least competitive with the better generative models in the literature and highlight the potential of the<br>adversarial framework.<br>6 Advantages and disadvantages<br>This new framework comes with advantages and disadvantages relative to previous modeling frame-<br>works. The disadvantages are primarily that there is no explicit representation of pg(x), and thatD<br>must be synchronized well with Gduring training (in particular, Gmust not be trained too much<br>without updating D, in order to avoid ‚Äúthe Helvetica scenario‚Äù in which Gcollapses too many values<br>ofzto the same value of xto have enough diversity to model pdata), much as the negative chains of a<br>Boltzmann machine must be kept up to date between learning steps. The advantages are that Markov<br>chains are never needed, only backprop is used to obtain gradients, no inference is needed during<br>learning, and a wide variety of functions can be incorporated into the model. Table 2 summarizes<br>the comparison of generative adversarial nets with other generative modeling approaches.<br>The aforementioned advantages are primarily computational. Adversarial models may also gain<br>some statistical advantage from the generator network not being updated directly with data exam-<br>ples, but only with gradients Ô¨Çowing through the discriminator. This means that components of the<br>input are not copied directly into the generator‚Äôs parameters. Another advantage of adversarial net-<br>works is that they can represent very sharp, even degenerate distributions, while methods based on<br>Markov chains require that the distribution be somewhat blurry in order for the chains to be able to<br>mix between modes.<br>7 Conclusions and future work<br>This framework admits many straightforward extensions:<br>6a) b)<br>c) d)<br>Figure 2: Visualization of samples from the model. Rightmost column shows the nearest training example of<br>the neighboring sample, in order to demonstrate that the model has not memorized the training set. Samples<br>are fair random draws, not cherry-picked. Unlike most other visualizations of deep generative models, these<br>images show actual samples from the model distributions, not conditional means given samples of hidden units.<br>Moreover, these samples are uncorrelated because the sampling process does not depend on Markov chain<br>mixing. a) MNIST b) TFD c) CIFAR-10 (fully connected model) d) CIFAR-10 (convolutional discriminator<br>and ‚Äúdeconvolutional‚Äù generator)<br>Figure 3: Digits obtained by linearly interpolating between coordinates in zspace of the full model.<br>1. A conditional generative modelp(xjc)can be obtained by adding cas input to both GandD.<br>2.Learned approximate inference can be performed by training an auxiliary network to predict z<br>given x. This is similar to the inference net trained by the wake-sleep algorithm [<a href='#ref15' rid='ref15' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>15</a>] but with<br>the advantage that the inference net may be trained for a Ô¨Åxed generator net after the generator<br>net has Ô¨Ånished training.<br>3. One can approximately model all conditionals p(xSjx6S)whereSis a subset of the indices<br>ofxby training a family of conditional models that share parameters. Essentially, one can use<br>adversarial nets to implement a stochastic extension of the deterministic MP-DBM [<a href='#ref10' rid='ref10' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>10</a>].<br>4.Semi-supervised learning : features from the discriminator or inference net could improve perfor-<br>mance of classiÔ¨Åers when limited labeled data is available.<br>5.EfÔ¨Åciency improvements: training could be accelerated greatly by devising better methods for<br>coordinating GandDor determining better distributions to sample zfrom during training.<br>This paper has demonstrated the viability of the adversarial modeling framework, suggesting that<br>these research directions could prove useful.<br>7Deep directed<br>graphical modelsDeep undirected<br>graphical modelsGenerative<br>autoencodersAdversarial models<br>TrainingInference needed<br>during training.Inference needed<br>during training.<br>MCMC needed to<br>approximate<br>partition function<br>gradient.Enforced tradeoff<br>between mixing<br>and power of<br>reconstruction<br>generationSynchronizing the<br>discriminator with<br>the generator.<br>Helvetica.<br>InferenceLearned<br>approximate<br>inferenceVariational<br>inferenceMCMC-based<br>inferenceLearned<br>approximate<br>inference<br>Sampling No difÔ¨ÅcultiesRequires Markov<br>chainRequires Markov<br>chainNo difÔ¨Åculties<br>Evaluatingp(x)Intractable, may be<br>approximated with<br>AISIntractable, may be<br>approximated with<br>AISNot explicitly<br>represented, may be<br>approximated with<br>Parzen density<br>estimationNot explicitly<br>represented, may be<br>approximated with<br>Parzen density<br>estimation<br>Model designModels need to be<br>designed to work<br>with the desired<br>inference scheme<br>‚Äî some inference<br>schemes support<br>similar model<br>families as GANsCareful design<br>needed to ensure<br>multiple propertiesAny differentiable<br>function is<br>theoretically<br>permittedAny differentiable<br>function is<br>theoretically<br>permitted<br>Table 2: Challenges in generative modeling: a summary of the difÔ¨Åculties encountered by different approaches<br>to deep generative modeling for each of the major operations involving a model.<br>Acknowledgments<br>We would like to acknowledge Patrice Marcotte, Olivier Delalleau, Kyunghyun Cho, Guillaume<br>Alain and Jason Yosinski for helpful discussions. Yann Dauphin shared his Parzen window eval-<br>uation code with us. We would like to thank the developers of Pylearn2 [<a href='#ref11' rid='ref11' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>11</a>] and Theano [<a href='#ref6' rid='ref6' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>6</a>, <a href='#ref1' rid='ref1' class='bibr popnode' role='button' aria-expanded='false' aria-haspopup='true'>1</a>],<br>particularly Fr ¬¥ed¬¥eric Bastien who rushed a Theano feature speciÔ¨Åcally to beneÔ¨Åt this project. Ar-<br>naud Bergeron provided much-needed support with L ATEX typesetting. We would also like to thank<br>CIFAR, and Canada Research Chairs for funding, and Compute Canada, and Calcul Qu ¬¥ebec for<br>providing computational resources. Ian Goodfellow is supported by the 2013 Google Fellowship in<br>Deep Learning. Finally, we would like to thank Les Trois Brasseurs for stimulating our creativity.<br><div class="ref-cit-blk half_rhythm" id="ref1">[1] Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., and<br>Bengio, Y . (2012). Theano: new features and speed improvements. Deep Learning and Unsupervised<br>Feature Learning NIPS 2012 Workshop.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref3">[3] Bengio, Y ., Mesnil, G., Dauphin, Y ., and Rifai, S. (2013). Better mixing via deep representations. In<br>ICML‚Äô13 .<br></div><br><div class="ref-cit-blk half_rhythm" id="ref5">[5] Bengio, Y ., Thibodeau-Laufer, E., Alain, G., and Yosinski, J. (2014b). Deep generative stochastic net-<br>works trainable by backprop. In Proceedings of the 30th International Conference on Machine Learning<br>(ICML‚Äô14) .<br></div><br><div class="ref-cit-blk half_rhythm" id="ref7">[7] Breuleux, O., Bengio, Y ., and Vincent, P. (2011). Quickly generating representative samples from an<br>RBM-derived process. Neural Computation ,23(8), 2053‚Äì2073.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref9">[9] Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y . (2013a). Maxout networks.<br>InICML‚Äô2013 .<br></div><br><div class="ref-cit-blk half_rhythm" id="ref11">[11] Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V ., Mirza, M., Pascanu, R., Bergstra,<br>J., Bastien, F., and Bengio, Y . (2013c). Pylearn2: a machine learning research library. arXiv preprint<br>arXiv:1308.4214 .<br></div><br><div class="ref-cit-blk half_rhythm" id="ref13">[13] Gutmann, M. and Hyvarinen, A. (2010). Noise-contrastive estimation: A new estimation principle for<br>unnormalized statistical models. In Proceedings of The Thirteenth International Conference on ArtiÔ¨Åcial<br>Intelligence and Statistics (AISTATS‚Äô10) .<br></div><br><div class="ref-cit-blk half_rhythm" id="ref15">[15] Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. (1995). The wake-sleep algorithm for unsupervised<br>neural networks. Science ,268, 1558‚Äì1161.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref17">[17] Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y . (2009). What is the best multi-stage architecture<br>for object recognition? In Proc. International Conference on Computer Vision (ICCV‚Äô09) , pages 2146‚Äì2153.<br>IEEE.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref19">[19] Krizhevsky, A. and Hinton, G. (2009). Learning multiple layers of features from tiny images. Technical<br>report, University of Toronto.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref21">[21] LeCun, Y ., Bottou, L., Bengio, Y ., and Haffner, P. (1998). Gradient-based learning applied to document<br>recognition. Proceedings of the IEEE ,86(11), 2278‚Äì2324.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref23">[23] Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic backpropagation and approximate<br>inference in deep generative models. Technical report, arXiv:1401.4082.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref25">[25] Salakhutdinov, R. and Hinton, G. E. (2009). Deep Boltzmann machines. In AISTATS‚Äô2009 , pages 448‚Äì<br>455.<br></div><br><div class="ref-cit-blk half_rhythm" id="ref27">[27] Susskind, J., Anderson, A., and Hinton, G. E. (2010). The Toronto face dataset. Technical Report UTML<br>TR 2010-001, U. Toronto.<br></div><br>
  <!-- End of References -->
  <div id="body-link-poppers"><span></span></div>
  <script type="text/javascript">
    var nwds_version = "1.1.9-2";

    var meta_nwds_ver = document.createElement('meta');
    meta_nwds_ver.name = 'ncbi_nwds_ver';
    meta_nwds_ver.content = nwds_version;
    document.getElementsByTagName('head')[0].appendChild(meta_nwds_ver);

    var meta_nwds = document.createElement('meta');
    meta_nwds.name = 'ncbi_nwds';
    meta_nwds.content = 'yes';
    document.getElementsByTagName('head')[0].appendChild(meta_nwds);

    var alertsUrl = "js/alerts.js";
    if (typeof ncbiBaseUrl !== 'undefined') {
      alertsUrl = ncbiBaseUrl + alertsUrl;
    }
  </script>


  <!-- JavaScript -->
  <script src="js/output.0f72d6a64937.js"></script>


  <script src="https://code.jquery.com/jquery-3.5.0.min.js"
    integrity="sha256-xNzN2a4ltkB44Mc/Jz3pT4iU1cmeR0FkXs4pru/JxaQ=" crossorigin="anonymous">
    </script>
  <script>
    var fallbackJquery = "js/jquery-3.5.0.min.js";
    window.jQuery || document.write("<script src=" + fallbackJquery + "></script>")
  </script>


  <script src="js/output.a212a9fcf845.js"></script>
  <script src="js/output.7999321d1aac.js"></script>
  <script src="js/output.7ca436b2ea51.js"></script>
  <script src="js/output.f8422046fbe0.js"></script>
  <script src="js/output.ff40c7d85ff8.js"></script>
  <script src="js/output.a6a84a0ad361.js"></script>

  <script type="text/javascript" src="js/base.54110350c77632754ed7.js"></script>

  <script type="text/javascript">
    if (typeof jQuery !== 'undefined') {
      jQuery.migrateMute = true;
    }
  </script>
  <script type="text/javascript" src="js/content0.js"></script>
  <script type="text/javascript" src="js/jig.nojquery.min.js">//</script>
  <script type="text/javascript" src="js/common.min.js?_=3.18">//</script>
  <script type="text/javascript" src="js/NcbiTagServer.min.js?_=3.18">//</script>
  <script type="text/javascript" src="js/crb.min.js?_=3.18">//</script>
  <script type="text/javascript" src="js/jactions.min.js?_=3.18">//</script>
  <script type="text/javascript"
    src="js/content1.js">//</script>
  <link rel="stylesheet" href="css/content0.css" type="text/css" />
  <script type="text/javascript">window.name = "mainwindow";</script>

  <script type="text/javascript">var exports = {};</script>
  <script src="js/output.340a3b9cce7f.js"></script>
  <script src="js/output.6cf6664daa2b.js"></script>
  <script type="text/javascript" src="js/article.e0db9c31af5bbd095194.js"></script>
  <script type="text/javascript">
    window.ncbi.pmc.articlePage.init({ pageURL: '/pmc/articles/PMC8193482/', citeCookieName: 'pmc-cf' });
  </script>
  <script type="text/javascript" src="js/content2.js"> </script>
 </body>
</html>
        